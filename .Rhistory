names(covid19_data)
names(covid19_spt)
class(covid19_spt)
st_geometry(covid19_spt) <- NULL
class(covid19_spt)
covid19_spt_df <- st_geometry(covid19_spt) <- NULL
# Data manipulation, transformation and visualisation
library(tidyverse)
# Nice tables
library(kableExtra)
# Simple features (a standardised way to encode vector data ie. points, lines, polygons)
library(sf)
# Spatial objects conversion
library(sp)
# Thematic maps
library(tmap)
# Colour palettes
library(RColorBrewer)
# More colour palettes
library(viridis) # nice colour schemes
# Highlight data on plots
library(gghighlight)
# Analysing spatio-temporal data
library(STRbook)
library(spacetime)
# Date parsing and manipulation
library(lubridate)
# Exportable regression tables
library(jtools)
library(stargazer)
library(sjPlot)
# clear workspace
rm(list=ls())
# read ONS UTLA shapefile
utla_shp <- st_read("/Users/Franciscorowe/Dropbox/Francisco/uol/teaching/envs453/201920/w11/data/sta/ons_utla.shp")
# create table of locations
locs <- utla_shp %>% as.data.frame() %>%
dplyr::select(objct, cty19c, ctyu19nm, long, lat, st_rs)
# read time data frame
time <- read_csv("/Users/Franciscorowe/Dropbox/Francisco/uol/teaching/envs453/201920/w11/data/sta/reporting_dates.csv")
# read COVID-19 data in long format
covid19 <- read_csv("/Users/Franciscorowe/Dropbox/Francisco/uol/teaching/envs453/201920/w11/data/sta/covid19_cases.csv")
# read census and IMD data
censusimd <- read_csv("/Users/Franciscorowe/Dropbox/Francisco/uol/teaching/envs453/201920/w11/data/sta/2011census_2019imd_utla.csv")
# check the time structure used for reporting
head(covid19$date, 5)
# parsing data into a time stamp
covid19$date <- ymd(covid19$date)
class(covid19$date)
# separate date variable into day,week, month and year variables
covid19$day <- day(covid19$date)
covid19$week <- week(covid19$date) # week of the year
covid19$month <- month(covid19$date)
covid19$year <- year(covid19$date)
# join dfs
covid19_spt <- left_join(utla_shp, covid19, by = c("ctyu19nm" = "Area.name"))
# spatial fields
spat_part <- as(select(covid19_spt, -c(bng_e, bng_n, Area.code, Area.type, Daily.lab.confirmed.cases, Cumulative.lab.confirmed.cases, date, day, week, month, year)), Class = "Spatial")
# time stamp
temp_part <- covid19_spt$date
# data
covid19_data <- covid19_spt %>% dplyr::select(c(Area.code, Area.type, date, Daily.lab.confirmed.cases, Cumulative.lab.confirmed.cases, day, week, month, year)) %>%
as.data.frame()
# construct STIDF object
covid19_stobj <- STIDF(sp = spat_part, # spatial fields
time = temp_part, # time fields
data = covid19_data) # data
class(covid19_stobj)
# select pop data
pop <- censusimd %>% dplyr::select("UTLA19NM", "Residents", "Longterm_sick_or_disabled")
# join dfs
covid19_spt <- left_join(covid19_spt, pop,
by = c("ctyu19nm" = "UTLA19NM"))
covid19 <- left_join(covid19, pop, by = c("Area.name" = "UTLA19NM"))
# risk of cummulative covid-19 infection
covid19_spt$c_covid19_r <- round( (covid19_spt$Cumulative.lab.confirmed.cases / covid19_spt$Residents) * 100000)
covid19$c_covid19_r <- round( (covid19$Cumulative.lab.confirmed.cases / covid19$Residents) * 100000)
# rate of new covid-19 infection
covid19_spt$n_covid19_r <- round( (covid19_spt$Daily.lab.confirmed.cases / covid19_spt$Residents) * 100000)
covid19$n_covid19_r <- round( (covid19$Daily.lab.confirmed.cases / covid19$Residents) * 100000 )
covid19_spt_df <- st_geometry(covid19_spt) <- NULL
class(covid19_spt_df)
G <- auto_basis(data = covid19_spt[,c("long","lat")] %>%
SpatialPoints(),           # To sp obj
nres = 1,                         # One resolution
type = "Gaussian")                # Gaussian BFs
S <- eval_basis(basis = G,                       # basis functions
s = covid19_spt[,c("long","lat")] %>%
as.matrix()) %>%            # conv. to matrix
as.matrix()                                 # conv. to matrix
colnames(S) <- paste0("B", 1:ncol(S)) # assign column names
names(covid19_spt)
names(MOcarolinawren_long)
data("NOAA_df_1990", package = "STRbook")
Tmax <- filter(NOAA_df_1990,       # subset the data
proc == "Tmax" &     # only max temperature
month == 7 &         # July
year == 1993)        # year of 1993
names(NOAA_df_1990)
class(NOAA_df_1990$day)
pr <- select(NOAA_df_1990, -year, -month, -proc,   # and remove vars we
-julian, -date)
names(pr)
View(NOAA_df_1990)
Wren_df <- cbind(MOcarolinawren_long,S) %>%
select(-loc.ID, -t)
pr1 <- select(MOcarolinawren_long, -loc.ID, -t)
names(pr1)
names(MOcarolinawren_long)
names(covid19_spt)
View(covid19_spt)
covid19_spt <- covid19_spt %>% mutate(
lt_illness = Longterm_sick_or_disabled / Residents
)
m1_df <- cbind(covid19_spt, S) %>%
select(ctyu19nm, long, lat, day, lt_illness)
m1_df[1:3, 1:5]
m1_df <- cbind(covid19_spt, S) %>%
select(c_covid19_r, ctyu19nm, long, lat, day, lt_illness)
m1_df[1:3, 1:5]
m1_df <- cbind(covid19_spt, S) %>%
select(ctyu19nm, c_covid19_r, long, lat, day, lt_illness)
m1_df[1:3, 1:5]
reg_df <- cbind(covid19_spt, S) %>%
select(ctyu19nm, c_covid19_r, long, lat, day, lt_illness)
reg_df[1:3, 1:5]
eq1 <- c_covid19_r ~ (lon + lat + year)^2 + lt_illness
model1 <- lm(formula = eq1, data = reg_df)
eq1 <- c_covid19_r ~ long + lat + day + lt_illness
model1 <- lm(formula = eq1, data = reg_df)
eq1 <- c_covid19_r ~ (long + lat + day)^2 + lt_illness
model1 <- lm(formula = eq1, data = reg_df)
model1 %>% summary()
names(reg_df)
eq1 <- c_covid19_r ~ (long + lat + day)^2 + lt_illness + .
model1 <- lm(formula = eq1, data = select(reg_df, -ctyu19nm))
model1 %>% summary()
eq1 <- c_covid19_r ~ (long + lat + day)^2 + lt_illness + .
model1 <- lm(formula = eq1, data = select(reg_df, -ctyu19nm))
model1 %>% summary()
reg_df <- cbind(covid19_spt, S) %>%
select(ctyu19nm, c_covid19_r, long, lat, day, lt_illness)
reg_df[1:3, 1:5]
G <- auto_basis(data = covid19_spt[,c("long","lat")] %>%
SpatialPoints(),           # To sp obj
nres = 1,                         # One resolution
type = "Gaussian")                # Gaussian BFs
S <- eval_basis(basis = G,                       # basis functions
s = covid19_spt[,c("long","lat")] %>%
as.matrix()) %>%            # conv. to matrix
as.matrix()                                 # conv. to matrix
colnames(S) <- paste0("B", 1:ncol(S)) # assign column names
reg_df <- cbind(covid19_spt, S) %>%
select(ctyu19nm, c_covid19_r, long, lat, day, lt_illness)
reg_df[1:3, 1:5]
reg_df <- cbind(covid19_spt, S)
names(reg_df)
reg_df <- cbind(covid19_spt, S) %>%
select(ctyu19nm, c_covid19_r, long, lat, day, lt_illness, B1:B9)
reg_df[1:3, 1:5]
reg_df <- cbind(covid19_spt, S) %>%
select(ctyu19nm, c_covid19_r, long, lat, day, lt_illness, B1:B9)
reg_df[1:3, 1:5]
reg_df <- cbind(covid19_spt, S) %>%
select(ctyu19nm, c_covid19_r, long, lat, day, lt_illness, B1)
reg_df[1:3, 1:5]
reg_df <- cbind(covid19_spt, S) %>%
select(ctyu19nm, c_covid19_r, long, lat, day, lt_illness, B1:B9)
reg_df[1:3, 1:5]
#Wren_df <- cbind(MOcarolinawren_long,S) %>%
#  select(-loc.ID, -t)
#Wren_df[1:3, 1:5]
reg_df <- cbind(covid19_spt, S) %>%
select(ctyu19nm, c_covid19_r, long, lat, day, lt_illness, B1:B9)
reg_df[1:3, 1:5]
#Wren_df <- cbind(MOcarolinawren_long,S) %>%
#  select(-loc.ID, -t)
#Wren_df[1:3, 1:5]
reg_df <- cbind(covid19_spt, S) %>%
select(ctyu19nm, c_covid19_r, long, lat, day, lt_illness, B1:B9)
reg_df[1:3, 1:5]
#Wren_df <- cbind(MOcarolinawren_long,S) %>%
#  select(-loc.ID, -t)
#Wren_df[1:3, 1:5]
names(reg_df)
eq1 <- c_covid19_r ~ (long + lat + day)^2 + lt_illness + .
model1 <- lm(formula = eq1, data = select(reg_df, -ctyu19nm))
model1 %>% summary()
eq1 <- c_covid19_r ~ long + lat + day + lt_illness + .
model1 <- lm(formula = eq1, data = select(reg_df, -ctyu19nm))
model1 %>% summary()
poisson_m <- glm(eq1,
family = poisson("log"), # Poisson + log link
data = select(reg_df, -ctyu19nm))
poisson_m %>% summary()
qpoisson_m <- glm(eq1,
family = quasipoisson("log"), # QuasiPoisson + log link
data = select(reg_df, -ctyu19nm))
qpoisson_m %>% summary()
eq2 <- c_covid19_r ~ (long + lat + day)^2 + lt_illness + .
qpoisson_m2 <- glm(eq2,
family = quasipoisson("log"), # QuasiPoisson + log link
data = select(reg_df, -ctyu19nm))
qpoisson_m2 %>% summary()
glm.nb(e1,
data = select(reg_df, -ctyu19nm))
install.packages("MASS")
?ape()
?FRK
?MASS
?MASS()
library(MASS)
install.packages("MASS")
library(MASS)
glm.nb(e1,
data = select(reg_df, -ctyu19nm))
?lme4
# Data manipulation, transformation and visualisation
library(tidyverse)
# Nice tables
library(kableExtra)
# Simple features (a standardised way to encode vector data ie. points, lines, polygons)
library(sf)
# Spatial objects conversion
library(sp)
# Thematic maps
library(tmap)
# Nice colour schemes
library(viridis)
# Obtain correlation coefficients
library(corrplot)
# Highlight data on plots
library(gghighlight)
# Analysing spatio-temporal data
#library(STRbook)
library(spacetime)
# Date parsing and manipulation
library(lubridate)
# Applied statistics
library(MASS)
# Statistical tests for linear regression models
library(lmtest)
# Fit spatial random effects models
library(FRK)
# Exportable regression tables
library(jtools)
rm(list=ls())
utla_shp <- st_read("data/sta/ons_utla.shp")
View(utla_shp)
library(tidyverse)
library(here)
library(readxl)
library(lubridate)
library(googlesheets4)
install.packages("rvest")
library(rvest)
library(rvest)
lego_movie <- html("http://www.imdb.com/title/tt1490017/")
lego_movie <- xml2::html("http://www.imdb.com/title/tt1490017/")
lego_movie <- xml2::read_html("http://www.imdb.com/title/tt1490017/")
lego_movie
lego_movie %>%
html_node("strong span") %>%
html_text() %>%
as.numeric()
vignette("selectorgadget")
lego_movie %>%
html_nodes("#titleCast .itemprop span") %>%
html_text()
lego_movie %>%
html_nodes("td:nth-child(2) a") %>%
html_text()
rm(list=ls())
lego_movie <- xml2::read_html("https://en.wikipedia.org/wiki/List_of_incidents_of_xenophobia_and_racism_related_to_the_COVID-19_pandemic")
site <- xml2::read_html("https://en.wikipedia.org/wiki/List_of_incidents_of_xenophobia_and_racism_related_to_the_COVID-19_pandemic")
site
lego_movie %>%
html_node("#firstHeading , p") %>%
html_text()
b_text %>%
html_node("#firstHeading , p") %>%
html_text()
site <- xml2::read_html("https://en.wikipedia.org/wiki/List_of_incidents_of_xenophobia_and_racism_related_to_the_COVID-19_pandemic")
site %>%
html_node("#firstHeading , p") %>%
html_text()
site %>%
html_node("p") %>%
html_text()
site %>%
html_node("p") %>%
html_text()
rm(list=ls())
# specify the url
wpdia_url <- ("https://en.wikipedia.org/wiki/List_of_incidents_of_xenophobia_and_racism_related_to_the_COVID-19_pandemic")
# read the html
html_site <- read_html(wpdia_url)
txt_bd %>%
html_node(html_site, "p") %>%
html_text()
bd_text <- html_site %>%
html_node(html_site, "p") %>%
html_text()
bd_text <- html_site %>%
html_nodes("#firstHeading , p") %>%
html_text()
bd_text
? html_nodes
bd_text <- html_site %>%
html_nodes("#firstHeading , p") %>%
html_text()
html_text(bd_text, trim = TRUE)
?html_text(
?html_text()
)
library(tidyverse)
bd_text
length(bd_text)
text_df <- tibble(line = 1:length(bd_text), text = text)
text_df <- tibble(line = 1:length(bd_text))
View(text_df)
text_df <- tibble(line = 1:length(bd_text), text= bd_text)
text_df %>%
unnest_tokens(word, text)
library(tidytext)
install.packages("tidytext")
library(tidytext)
text_df %>%
unnest_tokens(word, text)
txt_tokens <- text_df %>%
unnest_tokens(word, text)
data(stop_words)
tidy_text <- text_df %>%
unnest_tokens(word, text)
data(stop_words)
tidy_text <- tidy_text %>%
anti_join(stop_words)
tidy_text <- text_df %>%
unnest_tokens(word, text)
data(stop_words)
tidy_text <- tidy_text %>%
anti_join(stop_words)
View(tidy_text)
?anti_join
tidy_txt %>%
count(word, sort = TRUE)
tidy_txt <- text_df %>%
unnest_tokens(word, text)
data(stop_words)
tidy_txt <- tidy_txt %>%
anti_join(stop_words)
tidy_txt %>%
count(word, sort = TRUE)
sort_words <- tidy_txt %>%
count(word, sort = TRUE)
View(sort_words)
?write_csv
?write_csv()
write_csv(sort_words, "/Users/Franciscorowe/Dropbox/Francisco/Research/grants/2020/iom/keywords/ekwords_wkpdia")
write_csv(sort_words, "/Users/Franciscorowe/Dropbox/Francisco/Research/grants/2020/iom/keywords/ekwords_wkpdia.csv")
write_csv(sort_words, "/Users/Franciscorowe/Dropbox/Francisco/Research/grants/2020/iom/keywords/ekwords_wkpdia.txt")
Sys.getenv("MAPBOX_TOKEN")
set_token(Sys.getenv("MAPBOX_TOKEN"))
rm(list=ls())
# Dependencies
library(tidyverse)
library(data.table)
library(mapdeck) # create an interactive flow map using mapdeck library
library(mapview) # export interactive map as a static image
library(htmlwidgets)
# read in the RDS file with the full OD flows between European regions
EU_flows <- readRDS("data/EU_OD_flows.rds")
unique(EU_flows$ISO_code)
# for each region run ??? function
# the result will :
# 1. omit the intra-regional flows;
# 2. filter flows in each country that are greater than 1,000,
# or top 5% flows in countries where the largest flow is smaller than 1,000
# 3. normalise width with this equation for each country:
# Width=3*flows between a pair of Origin and Destination regions / max(OD flow)
country_OD_list <- list() # creates a list
for (country in unique(EU_flows$ISO_code)) {
OD_long  <- subset(EU_flows, ISO_code == country)
# remove the flows within the same region
OD_long <- OD_long %>% filter(or != dest)
# filter the rows based on flows <> 1000
if(max(OD_long$flows) < 1000) {
OD_long <- OD_long[OD_long$flows > quantile(OD_long$flows , 0.95 ) , ]
} else {
OD_long <- OD_long[which(OD_long$flows >= 1000), ]
}
# weighting to be used in the width of lines
OD_long$line_width <- 3 * OD_long$flows/ max(OD_long$flows)
# create a separate list object for each country
country_OD_list[[country]] <- OD_long
}
# we use rbindlist function from data.table
# to combine the individual dataframes for each country to one
MergedData <- rbindlist(country_OD_list)
# mapdeck uses Mapbox maps, and to use Mapbox you need an access token.
#You can generate a token by following this link https://docs.mapbox.com/help/how-mapbox-works/access-tokens/
key <- Sys.getenv("MAPBOX_TOKEN")    ## put your own token here
setwd("/Users/Franciscorowe/Dropbox/Francisco/Research/in_progress/mapping_euflows/github/mappingeuflows")
getwd()
# Dependencies
library(tidyverse)
library(data.table)
library(mapdeck) # create an interactive flow map using mapdeck library
library(mapview) # export interactive map as a static image
library(htmlwidgets)
# read in the RDS file with the full OD flows between European regions
EU_flows <- readRDS("data/EU_OD_flows.rds")
unique(EU_flows$ISO_code)
# for each region run ??? function
# the result will :
# 1. omit the intra-regional flows;
# 2. filter flows in each country that are greater than 1,000,
# or top 5% flows in countries where the largest flow is smaller than 1,000
# 3. normalise width with this equation for each country:
# Width=3*flows between a pair of Origin and Destination regions / max(OD flow)
country_OD_list <- list() # creates a list
for (country in unique(EU_flows$ISO_code)) {
OD_long  <- subset(EU_flows, ISO_code == country)
# remove the flows within the same region
OD_long <- OD_long %>% filter(or != dest)
# filter the rows based on flows <> 1000
if(max(OD_long$flows) < 1000) {
OD_long <- OD_long[OD_long$flows > quantile(OD_long$flows , 0.95 ) , ]
} else {
OD_long <- OD_long[which(OD_long$flows >= 1000), ]
}
# weighting to be used in the width of lines
OD_long$line_width <- 3 * OD_long$flows/ max(OD_long$flows)
# create a separate list object for each country
country_OD_list[[country]] <- OD_long
}
# we use rbindlist function from data.table
# to combine the individual dataframes for each country to one
MergedData <- rbindlist(country_OD_list)
# mapdeck uses Mapbox maps, and to use Mapbox you need an access token.
#You can generate a token by following this link https://docs.mapbox.com/help/how-mapbox-works/access-tokens/
key <- Sys.getenv("MAPBOX_TOKEN")    ## put your own token here
flowmap_EU <- mapdeck( token = key, style = 'mapbox://styles/mapbox/dark-v9',
location = c(7.6, 46.3),  zoom = 10, max_zoom = 80, pitch = 45) %>%
add_arc(
data = MergedData
, origin = c("or_Lon", "or_Lat")
, destination = c("des_Lon", "des_Lat")
, stroke_width = "line_width"
, palette = "reds"
)
flowmap_EU
rm(list=ls())
#Dependencies
library(dplyr) # enables use of pipe operators
library(data.table) # large data table manipulation
library(mapdeck) # create an interactive flow map using mapdeck library
library(htmlwidgets) # save interactive map into a html format
# read in the RDS file with the full OD flows between European regions
EU_flows <- readRDS("./data/EU_OD_flows.rds")
# the result of the for-loop below will :
# 1. omit the intra-regional flows;
# 2. filter flows in each country that are greater than 1,000,
# or top 5% flows in countries where the largest flow is smaller than 1,000
# 3. normalise width with this equation for each country:
# Width=3*flows between a pair of Origin and Destination regions / max(OD flow)
country_OD_list <- list() # create an empty list
for (country in unique(EU_flows$ISO_code)) {
OD_long  <- subset(EU_flows, ISO_code == country)
# remove the flows within the same region
OD_long <- OD_long %>% filter(Origin != Destination)
# filter the rows based on flows <> 1000
if(max(OD_long$flows) < 1000) {
OD_long <- OD_long[OD_long$flows > quantile(OD_long$flows , 0.95 ) , ]
} else {
OD_long <- OD_long[which(OD_long$flows >= 1000), ]
}
# weighting to be used in the width of lines
OD_long$line_width <- 3 * OD_long$flows/ max(OD_long$flows)
# create a separate list object for each country
country_OD_list[[country]] <- OD_long
}
# we use rbindlist function from data.table
# to combine the individual dataframes for each country to one
MergedData <- rbindlist(country_OD_list)
# mapdeck uses Mapbox maps, and to use Mapbox you need an access token.
#You can generate a token by following this link https://docs.mapbox.com/help/how-mapbox-works/access-tokens/
key <- Sys.getenv("MAPBOX_TOKEN")    ## put your own token here
flowmap_EU <- mapdeck( token = key, style = 'mapbox://styles/mapbox/dark-v9',
location = c(7.6, 46.3), zoom = 6, pitch = 45) %>%
add_arc(
data = MergedData
, origin = c("or_Lon", "or_Lat")
, destination = c("des_Lon", "des_Lat")
, stroke_width = "line_width"
, palette = "reds"
)
# plot the interactive map
flowmap_EU
rm(-"flowmap_EU")
rm(list=setdiff(ls(), "flowmap_EU"))
View(flowmap_EU)
save.image("~/Dropbox/Francisco/Research/in_progress/mapping_euflows/github/mappingeuflows/data/flowmap_mapdeckobj.RData")
saveRDS(flowmap_EU, file = "./data/flowmap_mapdeckobj.rsd")
saveRDS(flowmap_EU, file = "./data/flowmap_mapdeckobj.rds")
rm(list=ls())
library(htmlwidgets)
library(htmltools)
library(widgetframe)
knitr::opts_chunk$set(collapse = TRUE)
flowmap_EU <- readRDS(file = "./data/flowmap_mapdeckobj.rds")
frameWidget(flowmap_EU, options = frameOptions(allowfullscreen = TRUE))
